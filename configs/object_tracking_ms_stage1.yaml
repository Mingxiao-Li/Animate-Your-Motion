pretrained_model_path: "./stable-diffusion-v1-4"
output_dir: "./outputs/gligen-model_scope"
root_path: "./modelscope/text-to-video"

train_data:
  name: gligen
  data_path: "./dataset/GLIGEN"
  dataset_names:
    FlickrGrounding:
      which_layer_text: before
      image_size: 256
      max_boxes_per_data: 30
      prob_use_caption: 0.5
      random_crop: True
      random_flip: False
      cat_input: True
      crop_ratio: 0.9
      pretrained_model_path: "./stable-diffusion-v1-4"
    SBUGrounding:
      which_layer_text: before
      image_size: 256
      max_boxes_per_data: 30
      prob_use_caption: 0.5
      random_crop: True
      random_flip: False
      cat_input: True
      crop_ratio: 0.9
      pretrained_model_path: "./stable-diffusion-v1-4"
    VGGrounding:
      which_layer_text: before
      image_size: 256
      max_boxes_per_data: 30
      prob_use_caption: 0.5
      random_crop: True
      random_flip: False
      cat_input: True
      crop_ratio: 0.9
      pretrained_model_path: "./stable-diffusion-v1-4"

validation_data:
  video_length: 1
  width: 256
  height: 256
  num_inference_steps: 50
  guidance_scale: 12.5
  use_inv_latent: True
  num_inv_steps: 50

tracker:
  entity: bobwan
  project: video-diffusion
  group: gligen

learning_rate: 3e-5
train_batch_size: 2
val_batch_size: 2
max_train_steps: 200000
checkpointing_steps: 10000
validation_steps: 50000
trainable_modules:
  - "position_net"
  - "gate_attn"

seed: 33
mixed_precision: fp16
use_8bit_adam: False
gradient_checkpointing: True
enable_xformers_memory_efficient_attention: True
