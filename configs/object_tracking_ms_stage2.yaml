pretrained_model_path: "./stable-diffusion-v1-4"
output_dir: "./outputs/gligen-model_scope"
root_path: "/staging/leuven/stg_00116/modelscope/text-to-video"

train_data:
  name: object_tracking
  path: "/data/leuven/333/vsc33366/projects/Diffusion-Video/dataset"
  datasets:
    - "got10k"
    - "youvis"
  n_sample_frames: 8 
  width: 256
  height: 256
  split: "train"
  num_max_obj: 8

tracker:
  entity: use-name
  project: video-diffusion
  group: object-tracking

learning_rate: 5e-5
train_batch_size: 2
val_batch_size: 2
max_train_steps: 200000
checkpointing_steps: 10000
validation_steps: 50000
trainable_modules:
  - "gate_attn.cross"
  - "gate_attn.v"
  - "2.transformer_blocks"
  - "input_blocks.0.0" 

seed: 33
mixed_precision: fp16
use_8bit_adam: False
gradient_checkpointing: True
enable_xformers_memory_efficient_attention: True

# the root path refers to the pretrained model-scope text to video folder , you can download it from https://huggingface.co/ali-vilab/modelscope-damo-text-to-video-synthesis/tree/main